{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
    
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer Models\n",
        "\n",
        "## What is NLP?\n",
        "\n",
        "NLP is a field of linguistics and machine learning focused on understanding everything related to human language. The aim of NLP tasks is not only to understand single words individually, but to be able to understand the context of those words.\n",
        "\n",
        "## What is LLM?\n",
        "\n",
        "A large language model (LLM) is an AI model trained on massive amounts of text data that can understand and generate human-like text, recognize patterns in language, and perform a wide variety of language tasks without task-specific training. They represent a significant advancement in the field of natural language processing (NLP).\n",
        "\n",
        "## What can transformers do?\n",
        "\n",
        "The most basic object in the Transformers library is the `pipeline()` function. It connects a model with its necessary preprocessing and postprocessing steps, allowing us to directly input any text and get an intelligible answer:"
      ],
      "metadata": {
        "id": "vWdAOOdTCvRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "HFyPArDcFX_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347,
          "referenced_widgets": [
            "d18ae1c7b87c4d63a155b1c119fce2f2",
            "d5ecfc5fe48f4748b0468a7292e88cd1",
            "2a4dc9223e28414c96034530af439d5b",
            "fba336fb4fe841b4a127aa695a335902",
            "b791aebb4bcb466f9cfd4cd3e4de7c4e",
            "f21ec435b7df4157ba411a7bff0a236f",
            "f002862392f9490886f96b6a3e79c8ea",
            "edf2243b98c740749ff6171f695373a4",
            "5deb01208d8d4653902b7b37e594c2e5",
            "696c11b5000b4c50a42beb8700154604",
            "f4cdf86756024da8b7327e03d8b20bab",
            "6ab7c4f916434c20867676dc08a8c5b1",
            "4cd2597412434a8aa7a007451e569fd2",
            "a6788cfcef7a45919c5f25ef561a96bc",
            "89f55cd652d748e591480b5b31e8d2ac",
            "9f8bbc61b7514cd88b0c8a92133452bc",
            "5a05dbbec7fe48d1ad346565aaf6c4b8",
            "ae3572c2758d4d4e86b12fc3768a7007",
            "8a93b0b75c644a58af3fc530fcb2b484",
            "94f3874f05104917ba0e0098ac5a5c84",
            "0aac88c9fde14cb7b25885bc55843c9b",
            "531d7f9650b34854a1018a90a97508a1",
            "8b189307a72243c0a84f13a1bd98ad59",
            "d6763da9846944c7a17047212f801c84",
            "d903b55431394b57ad80a5d19e1a434f",
            "766c340e28fd4442a2cdc2c9d7d4554f",
            "0caa7ab611594755998750d4f4de2c07",
            "a436ac38fa8a4f71b87e0b33a0b936f4",
            "b931dabd031f49ffa7d2ba8a0e6c6e51",
            "6befa6b5aa3c48e4a50343712349b47f",
            "ede740af33de490782b6ce5d3221f642",
            "2f555482209447c9bbc9cd25c4268f33",
            "8ea7500dabb343a79fb206e88cf3367d",
            "53e2a2311a6e458ea720270d966fd031",
            "89dd0eaba2e04613aac75000b50a51d2",
            "49febc2fa672446cb5e3af7d09fdbe98",
            "5a094b339c574a3789fdbc7392707003",
            "5c8dee54e3e44c0aa677af49c08b1cd9",
            "2b8212ade4d7472a8654282f6164f5a9",
            "00d1be6e4b94414fb990600f13f7d6c1",
            "c8c0931b74b84fdb96d3c0c53ca3e8a8",
            "62df18b6607b49cbad61775691aad51e",
            "9a848ac5687f4881afd72d8f76cbbc22",
            "280e98aa7c2d41fe8a8b11e54946c3ab"
          ]
        },
        "id": "vcX7bztkCocG",
        "outputId": "f18b920c-e2eb-4cda-827b-b31f34cedbcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d18ae1c7b87c4d63a155b1c119fce2f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ab7c4f916434c20867676dc08a8c5b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b189307a72243c0a84f13a1bd98ad59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53e2a2311a6e458ea720270d966fd031"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9598049521446228}]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zero-shot classification\n",
        "\n",
        "It allows you to specify which labels to use for the classification."
      ],
      "metadata": {
        "id": "c3YUIyJXHEsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "classifier(\n",
        "    [\"This is a course about the Transformer library\", \"I love money!\"],\n",
        "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx8Uo26qFoWI",
        "outputId": "79018fc9-a024-4864-96a3-03fa13a25952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'sequence': 'This is a course about the Transformer library',\n",
              "  'labels': ['education', 'business', 'politics'],\n",
              "  'scores': [0.9567621946334839, 0.031608760356903076, 0.011629056185483932]},\n",
              " {'sequence': 'I love money!',\n",
              "  'labels': ['business', 'politics', 'education'],\n",
              "  'scores': [0.7989078164100647, 0.1051742434501648, 0.09591798484325409]}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text generation\n",
        "\n",
        "You provide a prompt and the model will auto-complete it by generating the remaining text."
      ],
      "metadata": {
        "id": "zTQT1iaPJKDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text-generation\")\n",
        "generator(\"In this course, we will teach you how to\", num_return_sequences=2, max_length=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOPzaZkFHp6-",
        "outputId": "7e204120-188a-49e4-fb34-8f861c2bddbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=15) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'In this course, we will teach you how to create an effective, effective, fast and efficient system of monitoring and evaluating the Internet. It will also use those systems to inform and plan for new and unforeseen problems.\\n\\nWe will create a system based on the concepts of \"monitoring and evaluating the Internet\", that is, a system where the Internet is monitored, monitored, monitored, monitored.\\n\\nOur system will be based on the principles of \"monitoring and evaluating the Internet\".\\n\\n\"Monitoring and evaluating the Internet\" is a term commonly used to describe a system that is designed to measure the amount of traffic flowing through the Internet.\\n\\n\"Monitoring\" is a term used to describe a system that is designed to measure the amount of traffic flowing through the Internet.\\n\\n\"Monitoring\" is a term used to describe a system that is designed to measure the amount of traffic flowing through the Internet.\\n\\nThe \"Internet\" is a physical and digital environment that is connected to the Internet from a computer, network or other medium.\\n\\nIn this course, we will use the Internet to inform, educate, and motivate us.\\n\\nThe Internet is a physical and digital environment that is connected to the Internet from a computer, network or other medium.\\n\\nIn this course,'},\n",
              " {'generated_text': 'In this course, we will teach you how to make and use the most powerful PHP libraries. With this tutorial, you will learn how to use PHP and the latest PHP versions to create your own custom PHP applications. You will learn how to create a PHP application in just a few minutes with a PHP framework.\\n\\nThis course will also teach you how to create your own custom PHP applications using only PHP. You will also learn how to use PHP to create and use your own custom PHP applications using only PHP.\\n\\nPlease note that all of this course is an online course. You can download it by clicking here.\\n\\nRequirements\\n\\n1. PHP 5.5 or later\\n\\n2. PHP 8.1 or later\\n\\n3. PHP 5.6 or later\\n\\n4. PHP 7.x or later\\n\\n5. PHP 4.8 or later\\n\\n6. PHP 5.1 or later\\n\\n7. PHP 4.7 or later\\n\\n8. PHP 5.0 or later\\n\\n9. PHP 5.1 or later\\n\\n10. PHP 5.2 or later\\n\\n11. PHP 5.3 or later\\n\\n12. PHP 5.4 or later\\n\\n13. PHP 5.5 or later\\n\\n14. PHP 5.6'}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using any model from the Hub in a pipeline\n",
        "\n",
        "We used the default models earlier but we can always use other models provided too."
      ],
      "metadata": {
        "id": "87BsLF9uMstZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text-generation\", model=\"HuggingFaceTB/SmolLM2-360M\")\n",
        "generator(\n",
        "    \"In this course, we will teach you how to\",\n",
        "    max_length=30,\n",
        "    num_return_sequences=2,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 946,
          "referenced_widgets": [
            "6e53d807ee0447019fd179031c7f0eb6",
            "1e1e7ced52814a9894e15849b650c216",
            "8248bb7ac24b4815868e86de9f31c3a9",
            "e2c01749266448fb9347cc256ac6a7c9",
            "08f226ba34414bc69e6329573221c241",
            "6bbc03f56cb6469c9456b641619fa106",
            "cd02c664d24b4145baf3b1b7c8194f44",
            "142a5904da1e4842b0aec48c051b1de7",
            "6226738172a74cf398eb2b5d47425f8e",
            "f24be401b3e64a789604bb8f0c2cc227",
            "f93c50b67f3b46ac8445811aee3422f2",
            "cf2f546f529748f0bcfa80c56ff437a1",
            "84d0aca1ceff4d5c9ae0c6f2486328ea",
            "a43eb34c001847238471db16e3279865",
            "22c98b9e08414c8ba0519d58d55393c3",
            "823a54ff3b2d4fcc9e97d6830fcd7641",
            "15005f8b52004cd4af4f2724ee5c4c73",
            "705abbb075724c9d8d5b897baac38f3f",
            "7e5c9a942663429c84bab84a951b827f",
            "6b2beef423494add91cb0fb2a3595146",
            "b9e53aa3d5944f8f83a1e6cb5b9b8f04",
            "7a7d4bf2bbd04a63bc0f9524192e11e8",
            "f19e7d0d628c4490b455784148d00b9c",
            "5a1cb26b9d714961b83a37d34f392b9b",
            "133de503398c405a92676337f79293f9",
            "05a32ff1eae44eb18d13adf7a013f5bc",
            "297a867444544d1ebb6bd190a5c46529",
            "6d9268c55a604d59b58db4af8f2da40b",
            "f0cd623dd7164d388d426600313d8223",
            "7496082fb987452da4d6d5ce08a268ed",
            "059c10bdd261407ea263162a5828dd5f",
            "711f5081a89c4046bb819a9fd2e25320",
            "c37fb6151bfd4f18b44c91a945ad8e80",
            "50edbcc36dcf409db571213bd0302b1b",
            "61343c3adade4919bb06bd0e9fe0668b",
            "b60e0b3522ff48a38be2ebb63f0548cb",
            "2c3fa51446a042a58293b76fb60aba82",
            "c9a3633b33c24517a4e481431345e89c",
            "78171f68379246ea8b8f559486aec618",
            "7a487962366e4c43b7c6642ef4ea5414",
            "00c9652ddac74dcc83c35fb8b3ce4bbe",
            "f8f7ff78178e461f81e0cbff81a3dab3",
            "8cd90d26bfc443899e0adcb7b9d388b2",
            "4973233ce0e74517b392b47d73000519",
            "4adfa452ab8247fa85f792893c94b0c1",
            "f566d7cd5eaa4d4f97bc941848d39816",
            "fc7dbe4a91384e2693a4d791f47420c6",
            "c9725224ac744004a073c98034f9ce9f",
            "75c02662983f4fcbb954faa330e14b8b",
            "5df18d9893d146eaa98d7da538a96e96",
            "c72cf2a8e17849f29260f12d4ba1c8b2",
            "0fd97857267e4dd492200b03a142c722",
            "d0555801b7b04e758b64421842e1c60a",
            "21ef693e41354e23ba4fcf24c68abefa",
            "230a479c3f224551ab0f7405603d5b47",
            "5fd1ca4f71d04a83a05f5eec2f2811ba",
            "9f1c710ec5a44813b3eacb0ee14b17ec",
            "d8bf6f9a2e334c6c90806a649f082374",
            "f0380f7f3d8c4ec3ac7ffeccede648a2",
            "d851e5891f76450e9b528419739507cd",
            "e1f0cdad5e254ee3b82b5836d82b7fe0",
            "dfa5360da3244c80adcf6448d48d9f9b",
            "88efda2a6c854de09568a3ade57a550e",
            "0d6c4694a44c4cb88a2a345abe2af254",
            "eea2df284b6f466d8b4683353c6a4da8",
            "2f6f26fbcc564ccf9bc8edfbdb5345ca",
            "cedfb9c787dd47dbaafc9fddc47967b2",
            "ea38c5f95268413abf11533f44697e0e",
            "14b2d54380e84acca3ee2dbe7bcf513d",
            "f6b301e887f34873a0b54f1f2178166c",
            "db36580c563e4f46b2ebcf7b4b2bfc8d",
            "e739e266e9434d0c93d75118768b54f5",
            "1ac9009a3de2493e8adcd4fae80220ee",
            "f7bca02f784e41aa9ebfa6bcc93b9663",
            "51404372fcf647d89c147e951986f42a",
            "3580d44576b54526b03bb0e1900e7fbd",
            "2a1fcef1daf545d78ef50a17e444b41f",
            "f116c7ec57b94cefa83fa8a094c2b153",
            "3c7d10c99d754a7ba2e10a3065edc4c8",
            "8f4a7685ac85412bbd8c262881a0d7e0",
            "f5e3b6199fb446b1a46c8c3b1af763a0",
            "3c4bf3443fc94c7cb9f8d28eae59668b",
            "08874a72fe954b9f9e2c072fa942fea6",
            "f17656a9550c424fbc1a779cc3476874",
            "e19438aac33a4675bce2532ea617935a",
            "53a798f7b01540eca171068eefdf9b90",
            "eb6fe9d47be04e83b2a9a87f005dac45",
            "190db29a4c614c0cb8cc2e4f1764034d"
          ]
        },
        "id": "cyXd8nw5IgER",
        "outputId": "59e0ff85-d2be-44f8-b31d-abb4ea58ac54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/689 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e53d807ee0447019fd179031c7f0eb6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/724M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf2f546f529748f0bcfa80c56ff437a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f19e7d0d628c4490b455784148d00b9c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50edbcc36dcf409db571213bd0302b1b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4adfa452ab8247fa85f792893c94b0c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5fd1ca4f71d04a83a05f5eec2f2811ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cedfb9c787dd47dbaafc9fddc47967b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/831 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f116c7ec57b94cefa83fa8a094c2b153"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'In this course, we will teach you how to do it. We will teach you what you need to do and what the tools that we will use are.\\n\\nWhat is a database?\\n\\nA database is an organized collection of information. It is a place where you can store information about things.\\n\\nA database can be a website, a program on your computer, or a file on your hard drive.\\n\\nWhy do we need databases?\\n\\nWe use databases to store information. We use them for a lot of different things.\\n\\nOne of the things that we use them for is to store information about things that we do. For example, if we want to store information about our pets, we would use a database to store information about their names, their ages, and their breeds.\\n\\nAnother thing that we use them for is to store information about things that we want to buy. For example, if we want to buy a new pair of shoes, we would use a database to store information about the prices of those shoes.\\n\\nAnd one of the most important things that we use databases for is to store information about things that we want to sell. For example, if we want to sell a new computer to someone, we would use a database to store information about the price'},\n",
              " {'generated_text': 'In this course, we will teach you how to use these techniques to your advantage. You will learn how to use a wide range of techniques to strengthen and improve your game.\\n\\nYou will learn how to use your body to your advantage and how to use your mind to your advantage. You will learn how to play with confidence and how to avoid mistakes.\\n\\nYou will learn how to use your body to your advantage and how to use your mind to your advantage.\\n\\nYou will learn how to play with confidence and how to avoid mistakes.\\n\\nYou will learn how to use your body to your advantage and how to use your mind to your advantage.\\n\\nYou will learn how to play with confidence and how to avoid mistakes.\\n\\nYou will learn how to use your body to your advantage and how to use your mind to your advantage.\\n\\nYou will learn how to play with confidence and how to avoid mistakes.\\n\\nYou will learn how to use your body to your advantage and how to use your mind to your advantage.\\n\\nYou will learn how to play with confidence and how to avoid mistakes.\\n\\nYou will learn how to use your body to your advantage and how to use your mind to your advantage.\\n\\nYou will learn how to play with confidence and how to avoid mistakes'}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, AutoTokenizer, GPT2LMHeadModel\n",
        "tokenizer = AutoTokenizer.from_pretrained('flax-community/gpt2-medium-persian')\n",
        "model = GPT2LMHeadModel.from_pretrained('flax-community/gpt2-medium-persian')\n",
        "generator = pipeline('text-generation', model, tokenizer=tokenizer, config={'max_length':100})\n",
        "generated_text = generator('در یک اتفاق شگفت انگیز، پژوهشگران')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245,
          "referenced_widgets": [
            "ec590770b47c4e209c01c8e6f8570698",
            "64e02e39fca945e9b8d6c5e7c1926936",
            "80ac334071cf4e0a83fe65023bf96a7a",
            "3dd45d3069434f328f8a277c47b38dc8",
            "51ef93c4d90040ca9f5ecb794f94d28b",
            "5adf047814b7462286eeac49826a3432",
            "d14fe0f88bd042f7a7187a1d15630fb1",
            "c96a0ce639414a65b7370c50fb721bc6",
            "5808594896664945ba90be18ad6cc396",
            "ca988b844c9c4df2995b4d060a3277de",
            "9c20c0c2b20b42dea3a3917b46840036",
            "f84825de0bdc4e449f16f912e6872358",
            "292d4a17d34149ed8f1798a523de53be",
            "ddfb0c1f361944adbf3e509f540058d1",
            "a5d3ec95cdf3489a94a0301b101651c0",
            "9ad900ad687e44fd96d64216b6146e0c",
            "3b691ede713e4023a0462f794773e21e",
            "1ee2fdb9a53045dea8467e5707106c39",
            "6650bbdcb162496086c09f34eaf4b4f4",
            "f0c84383ad474c66809036d331d398a0",
            "ed0520e235664ce4b04ca86d8eea11ed",
            "64e23b06191c483a82ae67e1458f77b2",
            "72aed530753b403ba120f4743d8183af",
            "e73a7df8fa514b33ad9825a4d6affc92",
            "3ba2843d61994910973baf17e92ba62f",
            "35b43c69040b4f42973600e0bbb338a5",
            "e67cf47d8d4a498093347a27e671be13",
            "e686bb7162974cf98fc38916479b0766",
            "41fb7b9fc2d147c1aca686b23704a92f",
            "e0e508149bed40aaa9b238c01495a946",
            "55026b9fd08c44a8b3abd387578b1b5e",
            "2735da9cc42247488d28fb295f415adc",
            "9b2a591aed5c40a9a90344e3b0550927",
            "e5fb3ba171484412b9cf075ba8ecb3c6",
            "1a44c1f7d9b644108b979c01251ac1c1",
            "c0d27a3c20df411b9850fdb245640dfb",
            "1624b03b60eb471992f56f8a8e394a63",
            "9a548da112f04959ba2ac63717577af2",
            "df665b06cc994c1ba7b77c5d048d87d8",
            "d05e9062027c4c47a2824e6f650e50dd",
            "c67d3d01a96845dbb6d12f9515be1ce2",
            "9bb304db454d4fe1afea0867ce711f8a",
            "12928e4e67c647a094aab5d8d6d33c90",
            "a173f6e778a040fab4e9762388f9831f",
            "97299a421a5e43cd9bdab3b68efad171",
            "14f7fcde213846868555edf218db363b",
            "4a3e35ffeefd4a8ea3d2900a410336b5",
            "bee69a9eaf144462829d782fdb6779d4",
            "f6574f97bb2f46f98f9a7525407f096d",
            "fd3d43a2eedb487bbec6eb43e8d7e4e8",
            "d35859dcd1794aeb8cc36d12f16a6e4a",
            "e1b7f181d53a46f7893e4aca38c70aac",
            "1c7cebd3c1fe44a381e8f4fe27cd9f6b",
            "c0d848e65eec43b79b10f774bd04806b",
            "92670d2a90bc436fb441bc1c61c57fe9",
            "33d1719d4f95454fbdd0fa42f09e1882",
            "32cce3d0984b4a898425dcc9c10543ea",
            "e7756364cacb45819d117934e245e58e",
            "c7fb564550514b8393546f4f5b995ea2",
            "cf3756abbed24cafabed964f69377400",
            "68c54b990e6746e28b086bbf6c12c3ee",
            "86b5b394064d410292278552ef62c9bf",
            "b404d6bfc9f84846a69991e381de6be4",
            "cfcacbd1201149c3b50bef672742b22e",
            "404dddb3df7a446a83177268a73f1db6",
            "e454ae03b2c94a31ad55e1b761415411"
          ]
        },
        "id": "Ow9hUhX_KDup",
        "outputId": "3cdf0a8e-eeaa-41ed-bb3a-5238c625785d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/921 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec590770b47c4e209c01c8e6f8570698"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f84825de0bdc4e449f16f912e6872358"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72aed530753b403ba120f4743d8183af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5fb3ba171484412b9cf075ba8ecb3c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.44G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97299a421a5e43cd9bdab3b68efad171"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.44G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33d1719d4f95454fbdd0fa42f09e1882"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Setting `pad_token_id` to `eos_token_id`:5 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhLyOP7NK53y",
        "outputId": "1149d434-5371-40ef-b1a7-73b4ac31433d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'در یک اتفاق شگفت انگیز، پژوهشگران دانشگاه\\u200cام آی تی نوعی پوست الکترونیکی ابداع کرده\\u200cاند که می\\u200cتواند به طور بالقوه برای درمان زخم\\u200cهای پوستی به کار گرفته شود. به گزارش ایسنا و به نقل از گیزمگ، زخم\\u200cهای پوستی، رایج\\u200cترین نوع از آسیب\\u200cهای پوستی هستند که به دلیل جراحت یا آسیب به بافت\\u200cهای بدن ایجاد می\\u200cشوند. این زخم\\u200cها می\\u200cتوانند در طول زمان، وخیم\\u200cتر شوند و به بافت\\u200cهای زیرین\\u200cتر پوست آسیب برسانند. به همین دلیل، پژوهشگران دانشگاه\\u200cام آی تی یک پوست الکترونیکی ابداع کرده\\u200cاند که قادر است از زخم\\u200cهای پوستی به عنوان یک ابزار تشخیصی استفاده کند. این پوست الکترونیکی، می\\u200cتواند به طور بالقوه برای درمان زخم\\u200cهای پوستی به کار گرفته شود. این پوست الکترونیکی که \"پوست الکترونیکی\"( e - wear ) نامیده می\\u200cشود، می\\u200cتواند به طور بالقوه برای درمان زخم\\u200cهای پوستی به کار گرفته شود. این پوست الکترونیکی از پوست انسان گرفته شده و می\\u200cتواند برای تشخیص زخم\\u200cهای پوستی مورد استفاده قرار گیرد. به گفته پژوهشگران، این پوست الکترونیکی جدید، \"می\\u200cتواند برای درمان زخم\\u200cهای پوستی یا برای بهبود زخم\\u200cها به کار رود، اما به جای استفاده از یک منبع نور، از یک تراشه الکترونیکی برای نشان دادن آسیب'}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, AutoTokenizer, GPT2LMHeadModel\n",
        "tokenizer = AutoTokenizer.from_pretrained('bolbolzaban/gpt2-persian')\n",
        "model = GPT2LMHeadModel.from_pretrained('bolbolzaban/gpt2-persian')\n",
        "generator = pipeline('text-generation', model, tokenizer=tokenizer, config={'max_length':256})\n",
        "sample = generator('در یک اتفاق شگفت انگیز، پژوهشگران')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp94nTPuMPV-",
        "outputId": "afc39578-5284-4a60-ee46-af763ffb5ecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-lJ_XjsMfGF",
        "outputId": "3e1d8c4e-db7f-4ed3-d7de-9b59654a2cdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'در یک اتفاق شگفت انگیز، پژوهشگران به گزارش خبرنگار گروه استان\\u200cهای باشگاه خبرنگاران جوان از قزوین ؛ مخاطبان صداوسیمای مرکز قزوین می\\u200cتوانند برنامه\\u200cهای مورد نظر خود را با مراجعه به این جدول پیگیری کنند.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mask filling\n",
        "\n",
        "The idea of this task is to fill in the blanks in a given text. The `top_k` argument controls how many possibilities you want to be displayed."
      ],
      "metadata": {
        "id": "vOz5j9LtNV62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unmasker = pipeline(\"fill-mask\")\n",
        "unmasker(\"This course will teach you all about <mask> models.\", top_k=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483,
          "referenced_widgets": [
            "7d6606396ebe47008035d194d36ed23e",
            "ffbfe9b074094f64a195e857e15447b9",
            "d8841ada987d439fbe06a3ba985be396",
            "ef18757f0e814497a3d62366cb54dc84",
            "d45225072fa94e63a3b649709d22e06e",
            "60d39ae0af064e86add64fbd8067795b",
            "860a81e9a4c14d66b5f3fc96895a5704",
            "451451be70c94eb0a90f1eb5c054d52e",
            "878e46c3f00f4408a588470a85ab7eb3",
            "48324f14e55145d2abdbbba8854cdcfc",
            "531e09f46c9145049f6b5953fcb3c94f",
            "bba9669d6ce3434fb90fbbc37501650e",
            "f6e5af6162d049118390fbd07c1747a2",
            "3e324033e74f4ba3aac72d3f74fe6907",
            "22b449bccc3d4258b5956857892fed50",
            "dba89d7a9ebd4b589da6118e2d172c5b",
            "2aef99c1ffbc48d6a5bf5441b043b7fa",
            "74b46dda4aa04eadb4cf2a5ca62a869a",
            "67b38247c09b4d6a94d67f1da8c09ca2",
            "f189ce048b5a407890e95e5eb6cdb60c",
            "e37626e6dc3f4ed5a2f5ffbb4030f511",
            "1e5e4ce01468424b98abf15e7710d756",
            "d69fd38f995344d8a102b35791d62ae6",
            "93e77e5fae10410bb375722cfdf3e0a4",
            "6be0eb0ac283459fa43a2db8b1d5ca2e",
            "e086012470f744259ff82367d9a278e9",
            "24cc1ec009b54f06b364bf9d94502fbc",
            "a64c9e32d6b745d3ab6a9b6c65de53a7",
            "2ce057d54bc441ce869f044424ad082a",
            "da3c4c8f671e4da7b3aa089074c53e0f",
            "ad0a5b394820446c9363edbec624bccf",
            "62a83513ddd64c14b2e38c87bf18ac56",
            "56fd8a1e519e492c88049de91d769f3d",
            "981bc69286144ab284fae58d63273d2e",
            "51f011a20dd5490b853034cbdc840f53",
            "14ab8a1f53584ab78962f1cab783ada0",
            "a0ab77773cae48efb19486d0662f0eb0",
            "724b1af4a61d47f69702ffb86ef690d6",
            "269d784c64e74df9bb2ce0cf391d8a3a",
            "708a3024eb1b465199cfe6e948925f28",
            "cefdb95156c64b018be8fd91213b49e3",
            "7d98ed5a83274725977e216387aaffaa",
            "5c1d34825c78475d976f8369071c98c8",
            "831b3b17558d4f719c41d7e909fbf8e1",
            "292644bf44c54ec1a3f6ca8896e716e1",
            "da32437f2ab94e57869117a826ad70ab",
            "a1a0f291e53f4834a30fd9d38cad6ebf",
            "62e5cced1fab464495f63755a4018a57",
            "7a282bad493e49e89d0877eb4e46b561",
            "97f89551f3c64b4793719e48d1d39a6d",
            "97dfc60dad1c4bbbb8a2221adbfa28fb",
            "897066c27dd14a33bf642b6fbdc3959d",
            "10c807b91ccc497dae49019ecf3f7c91",
            "9bc647eb3abf4844a2c916edc324d620",
            "b7de144c4516433db8dd98b5cdf6c06c",
            "59eb165a677d452ca9d0ea1a582e3d3a",
            "96e7f9884b614fd2a44d328d031c9aee",
            "0e1f3890f43c447d938ddf7eb8453a3f",
            "1da4b64e380b470da88444987dde3a6f",
            "251df205bb994c8eb8887e0065e7be3b",
            "3fc41c03d0454aaeb98c62bf13845d24",
            "6990c5969aae4dcf86a62fb78ea12866",
            "d620f26e3dca41bab311cadb5320a5bf",
            "96a10d773ca94bd1bb558f9fb1fedeee",
            "82705506bfa24df5812d11adc9d7d76b",
            "fae65fadaaf8493c9cb6285a3cb13169"
          ]
        },
        "id": "idnzOseqMkiN",
        "outputId": "43706962-bee7-42ef-eb48-ddacc37b41f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilroberta-base and revision fb53ab8 (https://huggingface.co/distilbert/distilroberta-base).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d6606396ebe47008035d194d36ed23e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/331M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bba9669d6ce3434fb90fbbc37501650e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d69fd38f995344d8a102b35791d62ae6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "981bc69286144ab284fae58d63273d2e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "292644bf44c54ec1a3f6ca8896e716e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59eb165a677d452ca9d0ea1a582e3d3a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.19619767367839813,\n",
              "  'token': 30412,\n",
              "  'token_str': ' mathematical',\n",
              "  'sequence': 'This course will teach you all about mathematical models.'},\n",
              " {'score': 0.04052715748548508,\n",
              "  'token': 38163,\n",
              "  'token_str': ' computational',\n",
              "  'sequence': 'This course will teach you all about computational models.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unmasker = pipeline('fill-mask', model='bert-base-cased')\n",
        "unmasker(\"This course will teach you all about [MASK] models.\", top_k=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383,
          "referenced_widgets": [
            "2807ed7dad9e49b0a76f179fd0f32c85",
            "d32bd396f02f4dadb57ee6d893c34391",
            "a2233b9d72aa42268c1485e18c14a39f",
            "d757b6144d02401c9738d60e3e5509a9",
            "8e228bc12ef54143ac4d8c6df0d0ba38",
            "3ccd39c971184ba19b9aae0ee235bd84",
            "457d7582b42d41f9901cb5c5c80e8c5a",
            "ec97a09f904a47fcb1d8acc16e588cd5",
            "1d6c1f8bd93a4b1d87c0c9b96e7fd925",
            "b71def8268e840ffb5b5f27a4b928d3e",
            "f30d20404fea40dca37053efcd267bf9",
            "0e7931a5506f43cdb4e44aeee97092af",
            "55889cd60b9f49d8bd134261c482f645",
            "135326b0236f422cbefe2cab80bbaa43",
            "de80581bb3034dec8325a2f9ee4fa6bf",
            "c7e5775522d443f8a9de0b375dc1f88d",
            "6da0cd66187e4048aa1436f689b7965a",
            "97919821cb0f4946b0f514ac336f9151",
            "e22af9b9cc13405d9b777bb20086d7c2",
            "96a801d5627f47d9ad6a87f60799ffdb",
            "58462746ce9944d1b4224cf703080ddd",
            "1fc58dadeac3458796c61863ba5306bd",
            "daa088cab72a4d7da0ad540c6ef0702e",
            "d7be3dbed81d48a78c3bc64821414d2f",
            "5ddc24fe249b4c128ac0746300a3efe5",
            "8bdd5dfad80b428e8e05efc88eed0d3c",
            "9c4caaf2eb7b4f4c9859d2614b6e07e4",
            "42ab92aafab1408296372af79731679d",
            "baf4c1ef01724eef8fdaddd58e51dcd0",
            "56ef8458ec5a45238a1f8681edec5c8a",
            "c818a725e188462b86bb659b8c189018",
            "3ca3020577c7449abd9d24819344f525",
            "0954ad58549949628161a98bd28962c6",
            "506a4e2e3dcd488d847fd1c6b9a56b62",
            "4e0a1edb4c584b8ba7ada05e550af28b",
            "953aede5b83f4a109f368b8088e8c73f",
            "cd9fede22177413b8805a08c99c2b4cc",
            "a3f26d8419974e2397c42e72d4516e35",
            "a9e87dce5fa443788aac59047d6a6d88",
            "36868a246c744ad1834f833dee75f2f3",
            "981fecb273d4492abb0b8739921f2ea0",
            "40de6e8b71bf4e3a9ca215adbe63b7d0",
            "b661b9d9172340afab6960c3eccd040b",
            "e62d10f8571c4ed08f971b0d04f8b354"
          ]
        },
        "id": "G4K8Fi_rNAw2",
        "outputId": "3f94f568-4d69-4567-d5ec-51560d24cf28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2807ed7dad9e49b0a76f179fd0f32c85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e7931a5506f43cdb4e44aeee97092af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "daa088cab72a4d7da0ad540c6ef0702e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "506a4e2e3dcd488d847fd1c6b9a56b62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.2596322000026703,\n",
              "  'token': 1648,\n",
              "  'token_str': 'role',\n",
              "  'sequence': 'This course will teach you all about role models.'},\n",
              " {'score': 0.09427239000797272,\n",
              "  'token': 1103,\n",
              "  'token_str': 'the',\n",
              "  'sequence': 'This course will teach you all about the models.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Named entity recognition\n",
        "\n",
        "Named entity recognition (NER) is a task where the model has to find which parts of the input text correspond to entities such as persons, locations, or organizations."
      ],
      "metadata": {
        "id": "RKUORCi_O_xL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ner = pipeline(\"ner\", grouped_entities=True)\n",
        "ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582,
          "referenced_widgets": [
            "b2f13ae86704444392382a828454d56c",
            "c6eb50c30f0a4cd3809aefbb6f5efcd0",
            "f757cc56541a44948ed0f6b8f2aa7ece",
            "37a4954966414c5ba906d60ea77a7dbd",
            "110301f81cdb4230a1ace250c0ecdae5",
            "30f6ec423a414e32b418c1846d153b55",
            "3c574c5adc134aa08a1472c230cda0fa",
            "17e6a1a42a92498dab79501ed1e34158",
            "eded94e020f54bfebf751c2403ce9030",
            "bdec2c82797c466a9595d6ca7fe70203",
            "50c8b2e707c14d80ba2eef79e32aab4d",
            "4b22404daa344bb787686145f6136656",
            "822cd3642b8e4c0e9338599f0f507e3a",
            "82bebd8abe04423cb1c1f6e6ab8563c6",
            "ec093d74221643b2ad1bf43344707832",
            "daff4f36d3cb435d9bd00cb9e6564e62",
            "4c0dbc3c36cf48a8a508de5d97cf989d",
            "70962b33a01246eebf02b2ac7ccc1712",
            "0ceee8c63a32475a8b812c80e74cdfa0",
            "6bb8e9c1b01e4f209749267d7b5fecbe",
            "ad0daec9976548b5afb2b9f9e457b299",
            "e3bb51e128a34ddcbf00110d7d2a84d9",
            "0029683380f04b55b2159a2820306039",
            "1e2e056b3bb64a528c8c5774f4f9bbfd",
            "5bbd43654626474d8387a3093c060e3c",
            "3b672b6c4a8d4e60945956e8c0aab22f",
            "2a1a2a751a564430a121c8167a765522",
            "2b952ad7e50746f28660957eb2e586ea",
            "6ad1968f65374231b3fbbd4caddfd49d",
            "1b6d7f4895594e839e5f22f97689dc20",
            "dbf5e51057f54a84828fb1efaf39a1c1",
            "b4889ee28267485c93877d906552506c",
            "552d71bc0751430f9ae889388f9b3606",
            "7b8b51b33f9546728cbe5141c2187357",
            "9473d9cffbd14c9488e973d0f362a81e",
            "c700ee4e85644655a71b7503fffc438c",
            "08cb71df618f44abb06ad6f454b352a1",
            "7acd07ef4b7f433a9791cf93e6674a83",
            "046a32270b99457188a9a781e6d14d47",
            "30168a6abf8d4604b51061cf2e973a84",
            "05d1df0d31584576ab5b946a184e8e00",
            "750735e9b1ce4b318025455db1032c29",
            "400907a51bce4d81bf2fe5f9936de00a",
            "e1338621a5f046198cd11952d5e57fad"
          ]
        },
        "id": "43HdDlhDN8jC",
        "outputId": "e7d27600-bef0-48bd-b18f-60c1c7268478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2f13ae86704444392382a828454d56c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b22404daa344bb787686145f6136656"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0029683380f04b55b2159a2820306039"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b8b51b33f9546728cbe5141c2187357"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/pipelines/token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': np.float32(0.9981694),\n",
              "  'word': 'Sylvain',\n",
              "  'start': 11,\n",
              "  'end': 18},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': np.float32(0.9796019),\n",
              "  'word': 'Hugging Face',\n",
              "  'start': 33,\n",
              "  'end': 45},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': np.float32(0.9932106),\n",
              "  'word': 'Brooklyn',\n",
              "  'start': 49,\n",
              "  'end': 57}]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question answering\n",
        "\n",
        "The `question-answering` pipeline answers questions using information from a given context:"
      ],
      "metadata": {
        "id": "NW6LIbiuPcml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question_answerer = pipeline(\"question-answering\")\n",
        "question_answerer(\n",
        "    question=\"Where do I work?\",\n",
        "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270,
          "referenced_widgets": [
            "1aaf1f0ef486449ea6fc93460ecb56ed",
            "26613ed7af2446fdb4f6b511f8c45b31",
            "5e931638f5b94c01b31264454f52f7c7",
            "cc07e9d490f74864b101b169ffc38632",
            "5fac19a497af4362b0ad0a361f146a26",
            "69198f5d0cf243c2aa9643d79c4e37fd",
            "fb09ee5643024928a30913fe6955017e",
            "da52cab9ebef4b47bdac18c426218597",
            "814d207b2e15463ebe869797bb074947",
            "9288009812874849af90bf8d81133147",
            "67b366e511c045acba1af1b055938b84",
            "488cb3a6eb984fc9afa332207f2f883e",
            "a8b08b8dbdd7498ab5d694c87d571887",
            "a821b91b39554a3fb967727705f09508",
            "7c69f84496614a2587b879a89ed3d048",
            "7a160e69ede84378bfa2ae01335b7c37",
            "434551f3863f4955b4873ba0ef254d5e",
            "de7f0d113fdc4f2eada6d0f8ba2573e1",
            "9a41776f942144f1b423522e8564350f",
            "6724bc7ed5e4480496e0e79fa945ae33",
            "545edeee691b45c2b080e10e143539c6",
            "d96c0493204b4a9e93b1423c7ae48fd1",
            "7fcea70f78e44a69b4d33f8b3d34546c",
            "3c57fccde7dd4d928112ab47cf87ee94",
            "46d86075a8e348be884c171c2dea4efc",
            "83e42c33f23044febec9ba75f162d239",
            "4e7d052fe26f410dbcb2c6472664927f",
            "af7e2c6534fc45d7924e5f7a07da06c7",
            "a8e49cf20f1b41c899dfe7168d75cf4d",
            "d1d2d7bf23564134b4c4a5e428835b6a",
            "ea3f9503dba74baa8fa454889f765186",
            "c1bbf3973528414eafccc5a30066573b",
            "f31ab56f61924262bad23f7f343068b2",
            "2afb7dfb867e4868b169836b0e38f34f",
            "722becc58a01401bacbb316684d9b673",
            "4a4efc8830f3443b8a455c667c34f667",
            "23bcb7da54cf49f6bfd7bfc4af807e72",
            "35670b6ad45f4548a16ccca810e0a4ea",
            "84f02de81b304b2493aaf022dcca0865",
            "aadaa06348684cde99459f6bbcdc95cf",
            "3933936b120d406c9c1004b9a909d82d",
            "70193c1d8f774f8fac37d731514657dd",
            "eef89a8005ac40209947c76df971de1e",
            "33e5b0584d5a4dce8957f4fc8225d244",
            "47102a3160f64b3182dbb56d53818345",
            "da0249b2d215421587fb043875d8e660",
            "99c7179259744a3ba19390c66120a5f1",
            "5a6a3df92b744819be2148733ef4e927",
            "12494008c31b41ffae6794ab123202d5",
            "b58418cea18740fd8e244e52b481f0e5",
            "d8fc01e89fc74ab78ea442ec921bc251",
            "14815b513d3a4a34867b35a84834166b",
            "4eff4ce16575414cb9d17fb7e20501e7",
            "56e63b465d604c6da239509302871a6d",
            "e3e11aeb6d334a838983afde70844daa"
          ]
        },
        "id": "gnVN0j9kOrCe",
        "outputId": "a9f784cb-94b7-4d6c-bd98-3a9681526eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1aaf1f0ef486449ea6fc93460ecb56ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "488cb3a6eb984fc9afa332207f2f883e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7fcea70f78e44a69b4d33f8b3d34546c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2afb7dfb867e4868b169836b0e38f34f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47102a3160f64b3182dbb56d53818345"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.6949766278266907, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summarization\n",
        "\n",
        "Summarization is the task of reducing a text into a shorter text while keeping all (or most) of the important aspects referenced in the text."
      ],
      "metadata": {
        "id": "4i5GmRHaPlkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\")\n",
        "summarizer(\n",
        "    \"\"\"\n",
        "    America has changed dramatically during recent years. Not only has the number of\n",
        "    graduates in traditional engineering disciplines such as mechanical, civil,\n",
        "    electrical, chemical, and aeronautical engineering declined, but in most of\n",
        "    the premier American universities engineering curricula now concentrate on\n",
        "    and encourage largely the study of engineering science. As a result, there\n",
        "    are declining offerings in engineering subjects dealing with infrastructure,\n",
        "    the environment, and related issues, and greater concentration on high\n",
        "    technology subjects, largely supporting increasingly complex scientific\n",
        "    developments. While the latter is important, it should not be at the expense\n",
        "    of more traditional engineering.\n",
        "\n",
        "    Rapidly developing economies such as China and India, as well as other\n",
        "    industrial countries in Europe and Asia, continue to encourage and advance\n",
        "    the teaching of engineering. Both China and India, respectively, graduate\n",
        "    six and eight times as many traditional engineers as does the United States.\n",
        "    Other industrial countries at minimum maintain their output, while America\n",
        "    suffers an increasingly serious decline in the number of engineering graduates\n",
        "    and a lack of well-educated engineers.\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374,
          "referenced_widgets": [
            "2ad0451dd7494da993fa2486324868f8",
            "c9bfe3d3835045e49f214c13f4109c8c",
            "39cc1e90c47b4a7b99baa0ea71543fec",
            "e370f69142874b46846d57923fb9a39e",
            "29b1726186e747979ec91e401018e4ad",
            "fa9d97ba8a034ac2ae32c26d8608caa7",
            "7e6e921eba1945658aedca2a76c98992",
            "0047673003c946f5a5289166e243767e",
            "56ad26c740e34efdb8b72bf11f082cba",
            "35ba370324cf4a6cbf3d210bab459b86",
            "c3f15379578641c3b810125c026bd7cb",
            "060419145f804e3091e4ee4970f8c6ce",
            "6c829b61c7c1414e8d11560c603a8c5d",
            "48ba0c8c9561497e8924d8dc29bdbcd5",
            "868ce0465a8a498d94ab3a8ad0c00f04",
            "e5391a06bca14c33a9a80b4fa356ed31",
            "a3e7bef0875d4f249a86d87e50ebedd1",
            "2a9090125b2e414891f8a93320121130",
            "8d9f6764a9044094b1dff8696ce084ed",
            "df37ce2beb3841b08b9e18f4b4bb28e6",
            "b0192d4141f54d63bf927ea4d6f8c941",
            "c8b0c748a0904102a14da6948b6f2221",
            "9e48a50dc5284e7c999b528656d79364",
            "cd462169c1e847149a8f0001a2138cd3",
            "ba24a8de63b94bfe9ac8b9711e3aa580",
            "156ada42161b49cead4d826c93e023c7",
            "fc634931ebbc4efa8b5d545d88a6484d",
            "eb2c8c79a43c404b8edd85ddf17c0364",
            "e24dd3ae977d4afb9623cf7a82ad930a",
            "fbb6135e19a045278070bab48dde639f",
            "d67e82c6f652436c8ab55f63a373f45d",
            "e69cd89a87794b3b88937d8a44fc03c7",
            "65f389bd763249ea9a50e60a53811946",
            "0ab0f0e4ae8f4b3d8e03c9fa15c38c60",
            "1550797709e64343936f46bb4d15bac6",
            "f4f8e96058884c96b7611b0f27e51dd7",
            "7c10c5554eb44504b5ce876747b22ef9",
            "2952e3d8e4ff49849f4ed1ffbc7e7b6a",
            "aade49b7ccdb407989d96d51af9e437f",
            "0b052865113c48fb8d6e7958aa50bb5b",
            "c2e882ecbe684300ad1694fcf43122e5",
            "6c171a6d3e9548e0a12754d0017cabae",
            "67c01df26a1543e79338cef20a5dd2d3",
            "4833c9593985428bb6ec97e993159097",
            "52b8a29f4fd542c7a5d0627743ccbb6c",
            "b67572f4e3294bc6a6fa2b27b0abf78a",
            "31501404852b4a55bb0b1c42b0d1549e",
            "2b7d2e7ce898402daff2ccc1e2f695d1",
            "fda388d3b5ef4b47a646d0d540b8a82c",
            "2b78ba5527db4d7da7b3dd7310ae0a06",
            "09b51235841d448a8d88df122f7acdc4",
            "9ef0cf1e2cae438bbb4eb39a6714e836",
            "ea23d8956b854df4a2b7576698ad1db6",
            "78e79f64493a4d5a859e2ca8c5ad84ea",
            "b3ea7a8c21bb47f88f94f8f22ae9896b",
            "7f2f946351c943b994eafd732b5bca15",
            "867e49fbf2f54be4aa1475a2bbb999c5",
            "9d1e7e439f294c5c9683a31acc9b1ec2",
            "e579c3d37cc54645b5c48745fb513abc",
            "b34616f52f3a49d1bcb61b999bcd357b",
            "ee5cd903dcb84b2a9bae81b4c540b243",
            "ceb66da5db4d4720bfd819a21b1465c9",
            "0a68c209f2834f4db25a0c5278c8bc5b",
            "33f941c1eff449f3bdc491a0bbf204af",
            "06cffb607d3c4377bd6b5339aed7089b",
            "96890844cf814ee08cc3e9b8dbc7306f"
          ]
        },
        "id": "DLLlLfnePU1e",
        "outputId": "b4de4178-2a96-4234-e658-39276bff1e1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ad0451dd7494da993fa2486324868f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "060419145f804e3091e4ee4970f8c6ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e48a50dc5284e7c999b528656d79364"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ab0f0e4ae8f4b3d8e03c9fa15c38c60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52b8a29f4fd542c7a5d0627743ccbb6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f2f946351c943b994eafd732b5bca15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': ' America has changed dramatically during recent years . The number of engineering graduates in the U.S. has declined in traditional engineering disciplines such as mechanical, civil,    electrical, chemical, and aeronautical engineering . Rapidly developing economies such as China and India continue to encourage and advance the teaching of engineering .'}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Translation"
      ],
      "metadata": {
        "id": "T9AUGN9uP6ti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translator = pipeline(\"translation\", model=\"omid-ebi/mT5_base_translation_English_to_Persian-Farsi\")\n",
        "translator(\"This is a github repository\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320,
          "referenced_widgets": [
            "a2b85815de0447f3b8501c5e8f408335",
            "dfc6e334cc8f4622ad9772f492763d8f",
            "f7de946d8b17409087fcc4b93887d6f7",
            "16d1c8c1570d44adb73abbbcaee627d3",
            "024336d850db4de6bb499664a936407f",
            "1d187d0d577e42c8af60d4d9d829f72c",
            "2aa6062f190f43c781bb2048a07edc91",
            "bd7d3cb24a8c4561a640e257467291a6",
            "9011bbee65674d52814d9af04474a6ff",
            "c1fe4feb698a49a3acc754fe5fa53866",
            "97f49ca6c58b4eab8ae08676f9c59928",
            "5c845b729d5549e8958dd349aae479fd",
            "2cb392d5a2574f8f900e8455317ccfa3",
            "b39c8dc9241d457fbf81070d46d37d9c",
            "ba584eba19564ca7801a88bc222a6d3c",
            "43e94d6c76dc4cd596ecd3e29a169061",
            "41f116864c544325a5ca9ec81696c18c",
            "44e748b21285469185b74ef3de75ee05",
            "8739af968aa84cd6ab1317762eca1bee",
            "29e2e4772d2948cb96598d1866d2ba3a",
            "0358eb0b63df4dee8d6771b641ec0238",
            "b2f919fc19c9476083a02d125a9d86ea",
            "40a8d031295140019ba01d45772d7e4a",
            "ea62c9adcad14561966d75bb52ef6d0c",
            "2ef99a63b07241c68fe8467032c005af",
            "1e93c1cd595147fababcdf932eadcdeb",
            "6daac8effab248cc94f3d67eb020b29f",
            "80bd4c919ba548a781393ceab33ace22",
            "b323662fc056447eaa50189209b030a4",
            "5a45af5aa4aa46ea976fa3730ce3f432",
            "491f0f91f6d1434cb562a5aa672389f6",
            "1e5da6b4910348b6bd731fcc5c2c0956",
            "2efc8810d9ed4413b1354cfb45f38787",
            "d36c9f16ba41481ba2e19116af794f8b",
            "36644ca8b20d4c5b865937a0bbd63ef0",
            "fc86c35fed884cd2a9419f22605f0746",
            "e8a5dc460baf4382a921f888c00e3b07",
            "ea06c86ce56346f298aac59b2701eb1c",
            "bc22a09bcfec4ab493c898c30cf9e852",
            "143ff8b4a3e54c80a31a53ab20cefd32",
            "5aa89c3e4cf3440ca2b825bc4a38f16e",
            "470474d509244e97b30ac6c069c9043d",
            "be0f4ac0afd4473795cccd85c24f7774",
            "9ca1af7b9733485b88108ee0f69a9624",
            "cd3ca84f685d49acad45be466b84faa4",
            "f8b1dadc3982483cab261a622fef6649",
            "14f8f0389b6149749bf74fbefb672583",
            "560d102c33ce46d580273bd00bc77556",
            "9b568ae99a164349b43125a63236a7d9",
            "cd7ce9c689a74c84a9772c6557207f55",
            "62560a73b67c459f98dd43dc3238c3fb",
            "3862cd39fc7f4a61b5bd6a22b9b12095",
            "426c99cb15d24cbe9345fc84abb4c778",
            "27dacd511a0145fe93b5d5f20091dfe1",
            "162a1bae91e34e7f8ba9740dfc416b16",
            "9bdb56edc4934d9dafa263a310561cde",
            "aca2b691ae75453c9d8043a15258dab5",
            "3eb42870335b49ccb6d1da55febc5aba",
            "1f1aa53a39d34c0982f5c0cc7b6ab7ed",
            "c4163f98f5dd45d18f6a75f0658415ca",
            "3f3ee26953974c4dbcd8340cf5f946fb",
            "240745b85549455bbddd99d64d9e5c23",
            "cbd80a97d8a74d97b7945d0296058eda",
            "e75c497778fb49289bf68ead27408bbe",
            "d2ad1172cc2e4280af9fd047cf689d93",
            "0c22a8e3a6b143aaafa60af1afe65df7"
          ]
        },
        "id": "jB829WY_Pphl",
        "outputId": "75d54315-4804-4a2d-ad12-2b9bfff51a2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/838 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2b85815de0447f3b8501c5e8f408335"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.33G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c845b729d5549e8958dd349aae479fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40a8d031295140019ba01d45772d7e4a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/881 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d36c9f16ba41481ba2e19116af794f8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd3ca84f685d49acad45be466b84faa4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/416 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9bdb56edc4934d9dafa263a310561cde"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'translation_text': 'این مطلب توسط مؤسسه ی گوردون است.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translator(\"In this session we will learn about NLP\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KIQHN8aQbtW",
        "outputId": "00ea521e-08dd-4b8e-e614-128ab4e4d095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'translation_text': 'در این جلسه ما درباره ی NLP یاد می کنیم.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How do Transformers work?\n",
        "\n",
        "_Pretraining_ is the act of training a model from scratch: the weights are randomly initialized, and the training starts without any prior knowledge. This pretraining is usually done on very large amounts of data. Therefore, it requires a very large corpus of data, and training can take up to several weeks.\n",
        "\n",
        "_Fine-tuning_, on the other hand, is the training done **after** a model has been pretrained. To perform fine-tuning, you first acquire a pretrained language model, then perform additional training with a dataset specific to your task.\n",
        "\n"
      ],
      "metadata": {
        "id": "BZoEIOxVRkh7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### General Transformer architecture\n",
        "\n",
        "The model is primarily composed of two blocks:\n",
        "\n",
        "- **Encoder**\n",
        "- **Decoder**\n",
        "\n",
        "Each of these parts can be used independently, depending on the task:\n",
        "\n",
        "- **Encoder-only models**: Good for tasks that require understanding of the input, such as sentence classification.\n",
        "\n",
        "- **Decoder-only models**: Good for generative tasks like text generation.\n",
        "\n",
        "- **Encoder-decoder models**: Good for generative tasks that require an input like translation or summarization."
      ],
      "metadata": {
        "id": "_O2BOvPqUrmC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How Transformers solve tasks\n",
        "\n",
        "### How language models work\n",
        "\n",
        "Two main approach for training a transformer model:\n",
        "\n",
        "1. **Masked language modeling (MLM)**: Allows model to learn bidirectional context. Used by encoder models like BERT.\n",
        "\n",
        "2. **Casual language modeling (CLM)**: The model can only use context from the left (previous tokens) to predict the next token. Used by decoder models like GPT.\n",
        "\n",
        "### Types of language models\n",
        "\n",
        "1. **Encoder-only models** (like BERT): These models use a bidirectional approach to understand context. They're suited for tasks that require deep understanding of text like classification.\n",
        "\n",
        "2. **Decoder-only models** (like GPT): These models process text from left to right and are particularly good at text generation tasks like completing sentences.\n",
        "\n",
        "3. **Encoder-decoder models** (like T5): These models combine two approaches, using an encoder to understand the input and a decoder to generate output. They excel at sequence-to-sequence tasks like translation.\n",
        "\n"
      ],
      "metadata": {
        "id": "0BuE1kskG0Bb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference with LLMs\n",
        "\n",
        "Inference is the process of using a trained LLM to generate human-like text from a given input prompt.\n",
        "\n",
        "### The Role of Attention\n",
        "\n",
        "When predicting the next word, not every word in a sentence carries equal weight. This ability to focus on relevant information is what we call attention.\n",
        "\n",
        "### The Two-Phase Inference Process\n",
        "\n",
        "Let's dive into how LLMs actually generate text. The process can be broken into two main phases: prefill and decode.\n",
        "\n",
        "#### The Prefill Phase\n",
        "\n",
        "This phase is where all the initial ingredients are processed and made ready. This phase involves three key steps:\n",
        "\n",
        "1. **Tokenization**: Convert the input text into tokens.\n",
        "\n",
        "2. **Embedding Conversion**: Transforming these tokens into numerical representations that capture their meaning.\n",
        "\n",
        "3. **Initial Processing**: Running the embeddings through the model's neural networks to create a rich understanding of the context.\n",
        "\n",
        "This phase processes all input tokens at once.\n",
        "\n",
        "#### The Decode Phase\n",
        "\n",
        "The decode phase involves several key steps that happen for each new token:\n",
        "\n",
        "1. **Attention Computation**: Looking back at all previous tokens to understand context\n",
        "\n",
        "2. **Probability Calculation**: Determining the likelihood of each possible next toke.\n",
        "\n",
        "3. **Token Selection**: Choosing the next token based on probablities\n",
        "\n",
        "4. **Continuation Check**: Deciding whether to continue or stop\n",
        "\n",
        "Thi phase is memory-intensive.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4prKyGzqZyEl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Excercises\n",
        "\n",
        "Ex1. An example to see pipeline working for different tasks."
      ],
      "metadata": {
        "id": "gWI2hPBj5P5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Sentiment analysis\n",
        "sentiment = pipeline(\"sentiment-analysis\")\n",
        "print(sentiment(\"I love learning NLP with Hugging Face!\"))\n",
        "\n",
        "# Text generation\n",
        "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "print(generator(\"In the future, artificial intelligence will\", max_length=30, num_return_sequences=1))\n",
        "\n",
        "# Fill mask\n",
        "fill_mask = pipeline(\"fill-mask\")\n",
        "print(fill_mask(\"Machine learning is <mask>.\"))\n",
        "\n",
        "# Named Entity Recognition\n",
        "ner = pipeline(\"ner\", grouped_entities=True)\n",
        "print(ner(\"Hugging Face is based in New York and works with Google.\"))\n"
      ],
      "metadata": {
        "id": "GRgjfWebRFab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e6b92666d27d43759b1d0c03b97efd7e",
            "a097eac9ec6f46d99e7d0de6ede922e8",
            "058c9fdc1995444da8a6a4e73cd7c0b1",
            "f3ab6176d447497aaac2ea7ceef47b73",
            "85888d661d374163971da0f64debb2b4",
            "b2223c536bab4478a7b33e62b5a6da63",
            "d548946d7ab54ae094ff762bd5d57c60",
            "8aed1825d7f64f2e97d6b8e561f3558b",
            "f93970cee3664ce2b3e30f5072c3d9ff",
            "61a5f2c581314093aed72b712fc7df5c",
            "caea69a7105a47bc857d893b0199e008",
            "9d5d6545db0647a98d3fc4890c876874",
            "49be1b7b1db84e7c91fbbf834283ee68",
            "9800ba8e65e844aa88cbbd33617b8219",
            "e385c356698040b5ac8e6c0860f25645",
            "7ad6a3eabe014993a426d14643063258",
            "493d835369cc4baf8915160453aff328",
            "a44652b87e364f798bed62c7801d4ec4",
            "fe16085c3d214f199f7714640a0c955a",
            "9e9a160a783945b0b5e6079dd47ab4cf",
            "e292b94c57d34b33abaad90729654173",
            "06d09189ed614a6485b009d35a38c6d9",
            "ec6832587e84426dba98554930115b29",
            "edb31484efc0463ba454aad8af6164d4",
            "ecbae8ec9a9b4675b94a060e09374141",
            "098c9ab788ef40888c9edff4caf9e36b",
            "92d43f44ac4547d8b32b1af5bcb457f9",
            "3d061c4991384327b559a59d3dc485bd",
            "118bd1f473f34bdda5d75d58d857f89f",
            "319f68fa70a3418a89ee6cf94bc01342",
            "3f7f800a6f974129a94abc0c06f6ce84",
            "e14d285a69e141149612a875dba8ee2f",
            "d27d2605111c460e9296c12e71af3b0a",
            "00b0babaa9724be98a25f82c1cfc2642",
            "ed981e2e04b443da9b10fbc416ae64a3",
            "548b2a3f2e584fb49db041a3fbda2c50",
            "beb7d3a683324214b9f1242ff5a13b55",
            "e35bbec8e8624202a56e952a49fc6289",
            "336dd26323fe47ca8823a74a9b83d14c",
            "b7a10e22d43940648d24032dc5d07b73",
            "d94f3f88df5243489145015e7d74d869",
            "e3ce2a86e7704aee9b98e4e42aba9ccc",
            "977444f9299a4fad8cd3c7ad11a7fdba",
            "a073b85eaaf44970a55dc9277aaba53d",
            "10fe0932d7624b3a853bb82155152fb0",
            "4a11b32570a142a9972937033bf5dd5e",
            "c4c26db694454cb190fa0a6232a11de2",
            "f4a8edf8508c47df979552674ff54344",
            "df668b990ba44b1ab2d16cd0c7144d5c",
            "a2fedbd9500042158be7b7c054ff0356",
            "fc706511c39347cea5f84a4b8ec0e6b4",
            "5cb1d675d76f4cadb5e39828b19ff1d3",
            "eefbde892f034df986880e710c0a8dc7",
            "cb74aa7ae6264346bd407d2a420384d8",
            "c1ab53e7d0fa4e0b9fddcb80de317424",
            "64c11a9e50794b8e8086589aa62582bc",
            "c1d3d3c3d74b49519fab5f96e6cc43ba",
            "ff0654146f324f13aa1b9b375673d671",
            "5e09201b8cd64e70ba44054e119cf1eb",
            "5cad9886a64e461ebd33767c0ce8635e",
            "4b1925ceda9d483b88ab3520a0dae2c7",
            "65d8756fdf6644ad8dfc9cc32a11fa93",
            "437ef2472dcb41ef94b4b621a1c92ca5",
            "8fafa24a8152416cb73ea2258fd5f625",
            "f8289c16769c4bcfa11026e83633f704",
            "f0efca15d8c641a692722f80259dcded",
            "61b6f9e3eb0a49e194a88d05c0da2030",
            "14aaf734b741405fbad709025887f5d2",
            "76b4d50136124d0c8b1ef0b743f334bf",
            "2f0f96f7dc7f4a47adecf38ea68306ec",
            "d22bb74c9b6a46e18a0fc448c6ef7a46",
            "8d028ac91fe74098a7fd93f0a3dbfc13",
            "1afb72f1ee714c5dbda9b54bc219c68d",
            "7c8664eee88846368dabcbd7d3ada063",
            "76ffcab8782549d79543992dc9c194d7",
            "8e7c69eccee34fd09c6cbd774aa67b07",
            "c99e301a1f6c46d59aa27294799cbfbf",
            "77766b25d00a49fdb52402f8d2029a45",
            "32f115bb3ffc4ee29c2f507a9d5d0d8d",
            "bb05ee5b19a048b5bb2ae329f6baa950",
            "de5c234eaf4245cdb3a29dde8ea74e3b",
            "fc561c201ae54993ba1b9b3845ff8fe5",
            "4ea62845ae254aee8ea4682efc29271a",
            "69442979c8ca49749a1cc0181c3fdbcf",
            "3b24002ed5344c459f3dc551c1d40007",
            "3e754907d45049428f5586c3c6369686",
            "8e94bb279c094dbdb36fb0a9d9ec3c1a",
            "b1f5c7ee7dc74479833ce4ff9e45bdc3",
            "597a9eea813b44f4be97bab133cdc1a2",
            "6a05079c21e9464ba79461499b62a4d8",
            "aa22db1fdd5d4054bc39b2cff49a68d1",
            "fdbfd543227b4fbb8741e083bee8dbc4",
            "e0e0a0634b67421c9ef268b736217ee2",
            "8367f9c5acee420f94e9c08da74a3df5",
            "a842b5a047ab403d84e3306188bba63f",
            "b6ba41f4ff7e409698d55033507825b0",
            "4a90f667b078465b99045bfd49c1044e",
            "702009a5431d4ca6a871d4fd1f9c6eb4",
            "879d7ff5f8834439862196571177b63c",
            "3e89a8a7ba62439facf5fbfaef28a6cd",
            "a4d6a223e15245c4b9ef990abfdead37",
            "0df6aefa305e448d94420db49b79b5d6",
            "77b0b3cce22142edb6f2662cec4e3815",
            "488a6ae0e7654906bbbc91e505b5178d",
            "9028b86ce9904816961e18c883db28fe",
            "4ea9cb70eaf64eb9a545efae30332e2d",
            "dbdd632cf7af48b88bbff0f31e04502c",
            "3977e34e51d048819fb2c4f4104f6e52",
            "b73f90c5bf3a432e832786c499e29b65",
            "3959432f087e4117a86720603a472910",
            "79bcd0108a93479d9955aebb02d2ebc0",
            "5b5842077d1143a3b6cf6c485bf03413",
            "863ad983175e4da082f0f31752e44ae4",
            "a47f10e78dfc4c81bda375dfa47bebff",
            "66d9cb42de9a4a73905ac7701db5867b",
            "37cfbc06a4aa482099075534936a6678",
            "87485f6c542b40d78fef742cf0c24469",
            "d89a4968a22748c780e1b5ddd9cf132c",
            "95530d597f1b435d8e3a31dea3dc87b6",
            "2f5dc4885ae74aef94164c7f7a35423b",
            "aea1a8d68b784486a5735a38e378ebf8",
            "0e6e8110a0fc42e39dfa36b2e51a98a4",
            "89a8f603beed45f891d2b7b8e4214a5a",
            "d919464d3cf9493e82d3f6b6ce67743f",
            "350a5b8e75f74f25aa463c89deef57a1",
            "1dcea5ecc1144b59a3c72d9e5a5bcdde",
            "42c860cf058649719d7f896e027f73b4",
            "2db2df0fdea44ee2be076fc17f4eb3a3",
            "589aec76d86a4897829d121082bb238d",
            "112c17e87dbc452a9e15a8a5c27cb96f",
            "d640ee528bee47aaa3b1d0d6dfc29d92",
            "105b9524a8ef4a9184a58e84dc3f5a44",
            "45ff5b877ff740cba5bd10e4a8208e3c",
            "22f9ca3603644c0eab111a24866d4c36",
            "f89dc5b9aba645bb9f66d62996204a5c",
            "6c15d747ddc24323a4fdc955c7e0500e",
            "35118a8d2ff34af9b7e9bab64db8f326",
            "b089fd5819bb495d91d3e26584d9f118",
            "4c405037938e45d084000a3c56c75e95",
            "de99adf8d0144929849dc3e7885d987a",
            "41c7dab7b3d240bf8d9760bf938472a7",
            "1bbd9a81b0654daabc1f300306d62d1f",
            "41da1f73f4f544f9ab7d10ee4610d570",
            "167c9f22183546cc97221c8f572c8d68",
            "03d509ef5e7c410f838a2406ea73751c",
            "6a2bf7d9620f4b72ad804778ae97a745",
            "c5b452f81a8149eda9a679e22e753789",
            "e9931cce0e17411a88de03685f449cee",
            "0d26b479cd38494da2f24f455d1a8bf3",
            "158c784629354e7cb05f198f8701a856",
            "c54d185059434af589b4741bc5408f6c",
            "7a9cc9e797ef4a17a0cef2c6a6eb7c7b",
            "78c387185cc647768907046f0d343bab",
            "65de02033c83438696c308e0e9e75293",
            "41d82dcff61342f9b6c6e2e3bb130841",
            "1a7709bb1ec84b2c83cf4288310eb3b1",
            "3d900862b1c74225af24f83117bd5d8c",
            "5fd8460cd6d8468c9225c0dba72c373a",
            "99bacb01a17048f0989e46b19d5f76e4",
            "26e54274ddf64188bb3b9b18a01632a6",
            "ea2427930d044e85ba03b50e30875e87",
            "5e0017fb45354aeea50539fdabc53481",
            "f8df476d4d8747bf800184760f9e8375",
            "0a51c00bd93f47c49d707ed54266c4ca",
            "2908615ab21d4350b54f5f8c4a5e93e8",
            "004ccfbce1414135a0cf8ec89fef2727",
            "d98528dd9df84353a490f190932120a6",
            "de5d4ca2d8a64a89a002f8ccf5724e9d",
            "6b450357bd5040d59c2ea85eb4e51d99",
            "01ee4b7fc8034af0942808c886671895",
            "57a98e9c61224d578f7db7229b494562",
            "3bcdcd7ba35f4f8594e7e65c68ab392b",
            "bf8c2fde842b42d8b70380702db2fe3a",
            "474aed0a80f446548cb8ec79f612b149",
            "1bf16d14f1c844079f54eb977c1c9b51",
            "806a92b61f104b9b9f4c04bb27ee1bcc",
            "59479a3feade4996b08faf18b6893eab",
            "753b0c306a814e9488fe652cfe63d77d",
            "5d9bbd72c68148d3b3ab9e43202dcd52",
            "3bb4ca1696b14adf96d92eecf3a76391",
            "9eea56c96fd24a0da14e438c2b29397b",
            "5db93d85f04b459db86ebb35d9cf2d6a",
            "9a4e490b2a75436ea9e3ad7c26ab75ab",
            "40f330ae254b4e9d8d527835a3833e4a",
            "7534287fc78c4417b53a35b592b9150e",
            "d9e1dcab916f4e96bcbbcb05c70b0496",
            "a1bdaff1216f4ed69ed7fbcac1bfe1d4",
            "0087b47c741342a7af3a9e42bdba934d",
            "8cf41da157e64af699f69539e488235d",
            "ed0531d7be394a1991f11cde02d92e86",
            "172e19bad45d438e8f4451d0ef563a65",
            "295d3e72170e4d469dc4ca07fb561dd5",
            "f4d4a714863f4dca8475bdc44657ac6a",
            "f12eacb37ca8416d88a656c66c75142f",
            "ed88d2ba2d4943e9b5b14a34d8a90df8",
            "397f5e0d8e5a4f758d5b52aacbf80692",
            "551fb6e9ba624ba1a62d8cf7706c77c5",
            "fef228b506b24db183bdffbe34da0ac6",
            "0bf557676b2e43208043c4e33a5d93b3",
            "efa475e69cf44651966323397fc23231",
            "8f29ede20a6d4e91ad50a79fa78d06cc",
            "5f5d0e3bb7f54acb8b323461cda862cf",
            "1ecd7aa5d8a443c8a0e18094fa8020bf",
            "380586961c4d4923b9a6976c20dfbfd2",
            "58031094210d45929edf64217c44504d",
            "12c895467f444a728c9179b473042e89",
            "7fb0127aa3804b3da620d56ed8e85454",
            "1237124b75ef46e69f4784f5d9d5f346",
            "bf4fdce5a92d4e1e8039e9955fe6693a",
            "69734ff4768c43898ec7ee33426efa43",
            "f2fde21c6d3b422bbf35a384653dd5de",
            "87c46a150e244fca91402369061e05fd",
            "ae6d5f6036cf474e87dd3b415fa19697",
            "455735187fce4ebcb3d8d267a4cf3a2a",
            "6d815bea99eb498ebfb82c564562e3fa",
            "4663e36834ee49528e12157aa50f1065",
            "65f5590cc9ae45b9adb97a060b006db1",
            "beb79ab6eef646ddb567746120265978",
            "ce478808672545618bcf768861daba9e",
            "bec81a5e43cd462d9aa720eccb9d7cce",
            "440a00fad7914153bc0a8aa6827e2c23",
            "5c60868af7b34c55aa3838584535d444",
            "05882d3771d24c898371f52bac5ac19b",
            "5c21266699b743da9a8e14b04b17537e",
            "36301215fb1c4a01a51810f107407949",
            "00bbd0d9de1f44dcb4c3a361c99b07d1",
            "0bf375a541434562b8a19809fce3b7f3",
            "1710d3de95974b81a3855a7c1cb94d90",
            "b5c22fd74ed24da38a8fac208fd9bd67",
            "b56ac8ca7a2142c2ab3e952e446794e5",
            "0822ace5695a4352b98d396f978af7be"
          ]
        },
        "outputId": "b5ab4f4a-7e37-4b97-bd38-6eb4c07d6da1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6b92666d27d43759b1d0c03b97efd7e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d5d6545db0647a98d3fc4890c876874"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec6832587e84426dba98554930115b29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00b0babaa9724be98a25f82c1cfc2642"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'POSITIVE', 'score': 0.9997377991676331}]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10fe0932d7624b3a853bb82155152fb0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64c11a9e50794b8e8086589aa62582bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61b6f9e3eb0a49e194a88d05c0da2030"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77766b25d00a49fdb52402f8d2029a45"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "597a9eea813b44f4be97bab133cdc1a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e89a8a7ba62439facf5fbfaef28a6cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79bcd0108a93479d9955aebb02d2ebc0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "No model was supplied, defaulted to distilbert/distilroberta-base and revision fb53ab8 (https://huggingface.co/distilbert/distilroberta-base).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': 'In the future, artificial intelligence will be able to detect and exploit a range of problems and solve them by the power of its algorithms. This is the kind of breakthrough that will be the envy of computer scientists, and will be something that will be taken into the next generation of computers in the 21st century.\\n\\nThe technology is already being developed by companies such as Autodesk, which is building a high-performance computer. It is currently being developed by Deep Blue. They have already been working on chips and hardware for their technology.\\n\\nWhat is the significance of this technological advance?\\n\\nAs mentioned, this is the \"first generation of artificial intelligence\", as opposed to the current generation of artificial intelligence. In the next generation, we are looking at a \"computer with a lot of power, but can do anything, and can\\'t be manipulated by a human being\". This means that the human brain is more capable than ever before.\\n\\nThis technology is the real key to the future of computing. We are seeing much of the development of this technology being done by companies such as Autodesk, who are developing chips for these very special tasks.\\n\\nWhat is the development process of these technology advancements?\\n\\nThe development process of these technology advancements is very gradual. For example,'}]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e6e8110a0fc42e39dfa36b2e51a98a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/331M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45ff5b877ff740cba5bd10e4a8208e3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "167c9f22183546cc97221c8f572c8d68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41d82dcff61342f9b6c6e2e3bb130841"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "004ccfbce1414135a0cf8ec89fef2727"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59479a3feade4996b08faf18b6893eab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'score': 0.030492667108774185, 'token': 4499, 'token_str': ' essential', 'sequence': 'Machine learning is essential.'}, {'score': 0.02547847479581833, 'token': 14007, 'token_str': ' evolving', 'sequence': 'Machine learning is evolving.'}, {'score': 0.02419901080429554, 'token': 2247, 'token_str': ' powerful', 'sequence': 'Machine learning is powerful.'}, {'score': 0.02404754050076008, 'token': 762, 'token_str': ' key', 'sequence': 'Machine learning is key.'}, {'score': 0.02292276732623577, 'token': 25107, 'token_str': ' ubiquitous', 'sequence': 'Machine learning is ubiquitous.'}]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0087b47c741342a7af3a9e42bdba934d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bf557676b2e43208043c4e33a5d93b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69734ff4768c43898ec7ee33426efa43"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "440a00fad7914153bc0a8aa6827e2c23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/pipelines/token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'entity_group': 'ORG', 'score': np.float32(0.95679855), 'word': 'Hugging Face', 'start': 0, 'end': 12}, {'entity_group': 'LOC', 'score': np.float32(0.99887264), 'word': 'New York', 'start': 25, 'end': 33}, {'entity_group': 'ORG', 'score': np.float32(0.99925536), 'word': 'Google', 'start': 49, 'end': 55}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ex2. For each `sentiment`, `ner` and `fill-mask` model explain what they do and what they are used for?\n",
        "\n",
        "\n",
        "`sentiment` models can detect if a sentence hase positive or negative meaning. It can be used to extract feelings from human talking.\n",
        "\n",
        "`ner` models can detect entities in a sentence. To know what a sentence mean it's essential to know which words are entities.\n",
        "\n",
        "`fill-masked` models can fill a part of an incomplete sentence. These can help programmers to code faster and more efficient by completing their codes."
      ],
      "metadata": {
        "id": "PoBGbFUY6msv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ex3. Try the code in Ex1 with a persian text and see the results."
      ],
      "metadata": {
        "id": "vI1G2DGD7wsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment = pipeline(\"sentiment-analysis\")\n",
        "print(sentiment(\"من عاشق برنامه نویسی هستم!\"))\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "print(generator(\"در آینده هوش مصنوعی\", max_length=30, num_return_sequences=1))\n",
        "\n",
        "fill_mask = pipeline(\"fill-mask\")\n",
        "print(fill_mask(\"یادگیری ماشین خیلی <mask>.\"))\n",
        "\n",
        "ner = pipeline(\"ner\", grouped_entities=True)\n",
        "print(ner(\"شرکت ما در تهران قرار دارد و با گوگل همکاری می‌کند\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZxfaTLa5jbH",
        "outputId": "6312313a-6d4d-4fa2-b752-72c0ca861595"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'POSITIVE', 'score': 0.7739375829696655}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "No model was supplied, defaulted to distilbert/distilroberta-base and revision fb53ab8 (https://huggingface.co/distilbert/distilroberta-base).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': 'در آینده هوش مصنوعی انتیرش تاقریه بنصر هوش مصنوعی انتیرش تاقریه هوش مصنوعی انتیرش تاقریه هوش مصنوعی انتیرش تاقریه هوش مصنوعی انتیرش تاقریه هوش مصنوعی انتیرش تاقریه هوش مصنوعی انتیرش تاقریه هوش مصنوعی انتیرش تاقریه هوش مصنوعی ا'}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n",
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'score': 0.22545477747917175, 'token': 30902, 'token_str': '\\u200e', 'sequence': 'یادگیری ماشین خیلی\\u200e.'}, {'score': 0.16830460727214813, 'token': 39004, 'token_str': 'د', 'sequence': 'یادگیری ماشین خیلید.'}, {'score': 0.1358729749917984, 'token': 29438, 'token_str': 'ا', 'sequence': 'یادگیری ماشین خیلیا.'}, {'score': 0.07894087582826614, 'token': 38605, 'token_str': 'ت', 'sequence': 'یادگیری ماشین خیلیت.'}, {'score': 0.07097788900136948, 'token': 40637, 'token_str': 'س', 'sequence': 'یادگیری ماشین خیلیس.'}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'entity_group': 'LOC', 'score': np.float32(0.43965322), 'word': 'ش', 'start': 0, 'end': 1}, {'entity_group': 'LOC', 'score': np.float32(0.57393897), 'word': 'تهران', 'start': 11, 'end': 16}, {'entity_group': 'LOC', 'score': np.float32(0.32940742), 'word': '##ر', 'start': 20, 'end': 21}, {'entity_group': 'ORG', 'score': np.float32(0.35137004), 'word': 'د', 'start': 22, 'end': 23}, {'entity_group': 'LOC', 'score': np.float32(0.2865751), 'word': '##د', 'start': 25, 'end': 26}, {'entity_group': 'LOC', 'score': np.float32(0.5538217), 'word': 'گ', 'start': 32, 'end': 33}, {'entity_group': 'LOC', 'score': np.float32(0.43421817), 'word': '##گل همکار', 'start': 34, 'end': 42}, {'entity_group': 'MISC', 'score': np.float32(0.31301263), 'word': '##ی', 'start': 42, 'end': 43}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see it didn't work very well with persian because it's trained on English sentences. To use these models on persian text we can use pretrained persian models and fine-tune them using our own dataset which is prepaired for our special purpose."
      ],
      "metadata": {
        "id": "1PMM92i2-YWi"
      }
    }
  ]
}